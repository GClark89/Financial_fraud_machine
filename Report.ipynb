{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# i. Which insights did you gain from your EDA? \n",
    "\n",
    "One of the most notable findings is the significant class imbalance, with 99.9% of transactions being non-fraudulent and only 0.1% being fraudulent. \n",
    "This imbalance matches my initial hyptheosis , and detecting fraud is a real challenge here.  We also noticed that most fraudulent transactions tend to be of the Transfer and Cash_out types, \n",
    "while Payment and Cash_in are generally non-fraudulent. Additionally, the IsFlaggedFraud feature doesn't seem very effective, as many fraudulent transactions, \n",
    "particularly Cash_out and Transfers, are not flagged at all. Larger transaction amounts were found to be more likely to be fraudulent, though they aren't always flagged.\n",
    "\n",
    "\n",
    "There were also some outliers in the Transfer and Cash_out categories, where large transactions were more often linked to fraudulent activity. \n",
    "These findings suggest that the current fraud detection model needs some fine-tuning, especially in identifying high-risk Transfer and Cash_out transactions. \n",
    "To improve detection, it might help to focus on features like transaction amounts or timing patterns, and consider more advanced \"unique\" detection or \n",
    "machine learning approaches for spotting these rare, high-risk events.\n",
    "\n",
    "\n",
    "# ii. How did you determine which columns to drop or keep? If your EDA informed this process, explain which insights you used to determine which columns were not needed. \n",
    "\n",
    "I removed the columns that seemed redundant initally. So that allowed me to get rid of 'nameDest'& 'nameOrig'. IsFlaggedFraud was dropped because there was not \n",
    "enough data in the coulumn. Only transaction type that was flagged was Transfers and that was certaintly not the only type that was actually fraud. \n",
    "Removing step was a tough decision but looking at my scatter plot i can see a lot of payment types happening at a cetain interval which surely could have possibly helped point \n",
    "out what transactions were fraud , with the class imbalance, i felt it wouldn't help much. i Think after running my model, i would like to use step just to compare the difference, \n",
    "if there is any. \n",
    "\n",
    "\n",
    "# iii. What was your final F1 Score? \n",
    "\n",
    "The final f1 score was .60. The intial and opitmized f1 score were the same. This indicates that the logistic regression model managed to strike a decent balance between precision and recall. \n",
    "In the context of fraud detection, it means the model was able to identify some fraudulent transactions, but it still made some errors, \n",
    "like false positives or false negatives. While an F1 score of 1.0 would be ideal, a score of 0.60 is a solid starting point, especially considering how challenging it can be to accurately detect fraud with imbalanced data. Given that the current model isn't performing well on the imbalanced data, I'd like to experiment with another machine learning model and explore techniques to balance the classes, aiming for a stronger and more accurate result.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
